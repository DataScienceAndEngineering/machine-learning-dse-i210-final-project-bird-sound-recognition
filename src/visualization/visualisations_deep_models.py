# -*- coding: utf-8 -*-
"""visualisations_deep_models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wlJTzQ7yq02Buqms4_JYfvthN5R03t4y
"""

import zipfile
import seaborn as sns
import cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import average_precision_score, f1_score, precision_score, recall_score, roc_auc_score
import tensorflow as tf
import keras
from make_dataset_deep import make_filepaths_labels, train_test_split_deep
from predict_model_deep import unzip_model_file, model_load_predict


def visualize_confusion_matrix(y_true, y_pred):
    confusion_mtx = tf.math.confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(10, 8))
    sns.heatmap(confusion_mtx,
            xticklabels=['bewickii','polyglottos','migratorius','melodia','cardinalis'],
            yticklabels=['bewickii','polyglottos','migratorius','melodia','cardinalis'],
            annot=True, fmt='g', cmap = 'Blues')
    plt.xlabel('Prediction')
    plt.ylabel('Label')
    plt.show()


def print_evaluation_metrics(y_true, y_pred, y_prob):
    f1 = f1_score(y_true, y_pred, average='macro')
    precision = precision_score(y_true, y_pred, average='macro')
    recall = recall_score(y_true, y_pred, average='macro')
    auc = roc_auc_score(y_true, y_prob, average='macro', multi_class='ovo')
    print(f"F1: {f1} | Precision: {precision} | Recall: {recall} | AUC: {auc}")


def compute_saliency_map(model, input):
    with tf.GradientTape() as tape:
        tape.watch(input)
        predictions = model(input, training=False)
        top_prediction = tf.argmax(predictions[0])
        top_class_output = predictions[:, top_prediction]

    gradients = tape.gradient(top_class_output, input)
    saliency_map = tf.reduce_max(tf.abs(gradients), axis=-1)
    return saliency_map[0]


# Please enter the indices of the test data that we want to visualize the Saliency Maps for
def visualize_saliency_map(model, dataset_test, test_data_indices_list):
      dataset_test_tensors = []
      for ds in dataset_test:
          mel = ds[0]
          dataset_test_tensors.append(mel)

      dataset_test_mels = [item for sublist in dataset_test_tensors for item in sublist]

      for i in test_data_indices_list:
          mel_spectrogram = dataset_test_mels[i]
          mel_spectrogram_expanded = mel_spectrogram[np.newaxis, ...]
          total_duration = 3
          num_bins = 1026
          time_per_bin = total_duration / num_bins
          time_axis = np.linspace(0, total_duration, num_bins)
          frequency_axis = np.arange(128)

          plt.figure(figsize=(10, 4))
          plt.imshow(np.transpose(mel_spectrogram), aspect='auto', origin='lower', cmap='viridis')

          saliency_map = compute_saliency_map(model, mel_spectrogram_expanded)
          saliency_map_reshaped = tf.repeat(tf.expand_dims(saliency_map, axis=1), repeats=128, axis=1)
          plt.figure(figsize=(10, 4))
          plt.imshow(np.transpose(mel_spectrogram), aspect='auto', origin='lower', cmap='viridis')
          plt.imshow(np.transpose(saliency_map_reshaped), aspect='auto', cmap='viridis', alpha=0.5, interpolation='nearest')
          plt.gca().invert_yaxis()
          plt.xlabel('Time Step')
          plt.ylabel('Frequency Bin')
          plt.title('Mel Spectrogram')
          cbar = plt.colorbar()
          cbar.set_label('Intensity')
          plt.show()


def main():
    features = ['LinearSpectrogram', 'MelSpectrogram', 'MFCC']
    metadata_path = '/content/drive/MyDrive/archive (17)/bird_songs_metadata.csv'
    audio_path = '/content/drive/MyDrive/archive (17)/wavfiles/'
    file_paths, labels = make_filepaths_labels(metadata_path, audio_path)
    dataset_train, dataset_test = train_test_split_deep(file_paths, labels, features[1])
    zip_file_path = '/model_CNN_mel.zip'
    extract_to_path = '/content/model'
    model_path = '/content/model'
    unzip_model_file(zip_file_path, extract_to_path)
    y_prob, y_pred, y_true = model_load_predict(model_path, dataset_test)
    visualize_confusion_matrix(y_true, y_pred)
    print_evaluation_metrics(y_true, y_pred, y_prob)
    visualize_saliency_map(tf.keras.models.load_model(model_path), dataset_test, [124, 346])


if __name__ == "__main__":
    main()